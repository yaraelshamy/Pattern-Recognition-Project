{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c413ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7ab163",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58491dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    \"\"\"\n",
    "    Loads each image in the given folder and save it in an array.\n",
    "    \n",
    "    In case of training data, it saves 3 copies of images:\n",
    "    original, flipped and rotated copies.\n",
    "    \n",
    "    Returns array of images and array of their labels.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    classes = 0\n",
    "    flag = 1\n",
    "    for file_name in os.listdir(folder):\n",
    "        if folder == 'Testing': flag = 0 \n",
    "        sub_dir_path = folder + '/' + file_name\n",
    "        for filename in os.listdir(sub_dir_path):     \n",
    "            try:\n",
    "                img = cv2.imread(os.path.join(sub_dir_path, filename))\n",
    "                img = cv2.resize(img, (224, 224))\n",
    "                flipped_img = cv2.flip(img, 0)\n",
    "                rotated_img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(' ')\n",
    "            \n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "                labels.append(classes)\n",
    "                if flag:\n",
    "                    images.append(flipped_img)\n",
    "                    images.append(rotated_img)\n",
    "                    labels.append(classes)\n",
    "                    labels.append(classes)\n",
    "\n",
    "        classes += 1\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b61639f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " \n",
      " \n",
      "1818 131\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels = load_images_from_folder(\"Training\")\n",
    "test_images, test_labels = load_images_from_folder(\"Testing\")\n",
    "print(len(train_images), len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53607225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Shape:(1818, 224, 224, 3) \n",
      "No. of Training Dataset Labels:1818 \n",
      "Test Dataset Shape:(131, 224, 224, 3) \n",
      "No. of Test Dataset Labels:131 \n"
     ]
    }
   ],
   "source": [
    "print('Training Dataset Shape:{} '.format(train_images.shape)) \n",
    "print('No. of Training Dataset Labels:{} '.format(len(train_labels))) \n",
    "print('Test Dataset Shape:{} '.format(test_images.shape))\n",
    "print('No. of Test Dataset Labels:{} '.format(len(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "181f800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_images)\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbcbacd",
   "metadata": {},
   "source": [
    "# Transfer Learning with TF Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c79f7e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor_model = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "\n",
    "pretrained_model_without_top_layer = hub.KerasLayer(\n",
    "    feature_extractor_model, input_shape=(224, 224, 3), trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53552fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 1280)              2257984   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                12810     \n",
      "=================================================================\n",
      "Total params: 2,270,794\n",
      "Trainable params: 12,810\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([pretrained_model_without_top_layer, tf.keras.layers.Dense(10)])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bec9e0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "57/57 [==============================] - 32s 554ms/step - loss: 0.9700 - acc: 0.7068\n",
      "Epoch 2/5\n",
      "57/57 [==============================] - 32s 568ms/step - loss: 0.3032 - acc: 0.9224\n",
      "Epoch 3/5\n",
      "57/57 [==============================] - 32s 567ms/step - loss: 0.2119 - acc: 0.9505\n",
      "Epoch 4/5\n",
      "57/57 [==============================] - 32s 564ms/step - loss: 0.1617 - acc: 0.9620\n",
      "Epoch 5/5\n",
      "57/57 [==============================] - 32s 567ms/step - loss: 0.1326 - acc: 0.9719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x163a50a3580>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer= \"adam\", loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['acc'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c7ab4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 32s 561ms/step - loss: 0.1182 - acc: 0.9719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11817973107099533, 0.971947193145752]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fb6f814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 344ms/step - loss: 0.6500 - acc: 0.8092\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6500393748283386, 0.8091602921485901]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3576151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.609363 ,  3.90926  , -3.836537 , -1.3031648, -3.2525444,\n",
       "        -3.481797 , -8.16926  , -1.932404 , -1.8995795, -4.3971186]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one trial\n",
    "\n",
    "img = cv2.imread('C:/Users/WIN 10/Documents/Pattern Semester Project/Project/Testing/dna\\dna_080.tif')\n",
    "img = img / 255.0\n",
    "img = cv2.resize(img, (224, 224))\n",
    "result = model.predict(img[np.newaxis, ...])\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
